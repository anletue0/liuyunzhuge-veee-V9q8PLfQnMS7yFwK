[合集 - 技术札纪——有限硬件与无限计算的权衡艺术(45)](https://github.com)

[1.书本介绍：技术札纪——有限硬件与无限计算的权衡艺术07-24](https://github.com/poemyang/p/19002322)[2.书本大纲：从芯片、分布式到云计算AI时代07-25](https://github.com/poemyang/p/19004265)[3.我的代码背叛了我？为什么 a=1, b=2，最后x和y都等于0？07-25](https://github.com/poemyang/p/19004704)[4.我的代码出现幻觉？说好的a = 1； x = b，怎么成了x = b； a = 1？07-28](https://github.com/poemyang/p/19008983)[5.为什么i++不是原子操作？一个让无数并发程序崩溃的“常识”07-29](https://github.com/poemyang/p/19010948)[6.没有Happens-Before？你的多线程代码就是‘一锅粥’！07-30](https://github.com/poemyang/p/19012883)[7.Hello World背后藏着什么秘密？一行代码看懂Java的“跨平台”魔法07-31](https://github.com/poemyang/p/19014740)[8.a+b=c，处理器一步搞定，Java虚拟机为啥要四步？08-01](https://github.com/poemyang/p/19016482)[9.“同声传译”还是“全文翻译”？为何HotSpot虚拟机仍要保留解释器？08-04](https://github.com/poemyang/p/19020937)[10.“代码跑着跑着，就变快了？”——揭秘Java性能幕后引擎：即时编译器08-05](https://github.com/poemyang/p/19022518)[11.Java编译器优化秘籍：字节码背后的IR魔法与常见技巧08-06](https://github.com/poemyang/p/19024509)[12.解锁硬件潜能：Java向量化计算，性能飙升W倍！08-07](https://github.com/poemyang/p/19026352)[13.new出来的对象，不一定在堆上？聊聊Java虚拟机的优化技术：逃逸分析08-08](https://github.com/poemyang/p/19027777)[14.性能优化之母：为什么说“方法内联”是编译器优化中最关键的一步棋？08-11](https://github.com/poemyang/p/19031406)[15.从纳秒到毫秒的“时空之旅”：CPU是如何看待内存与硬盘的？08-12](https://github.com/poemyang/p/19033086)[16.硬盘性能提升100倍的秘密：看懂顺序I/O的魔力08-14](https://github.com/poemyang/p/19038725)[17.十年大厂员工终明白：MySQL性能优化的尽头，是对B+树的极致理解08-18](https://github.com/poemyang/p/19043960)[18.Facebook内部都在用的存储引擎，LSM凭什么能硬扛亿级写入流量？08-21](https://github.com/poemyang/p/19050442)[19.千亿消息“过眼云烟”？Kafka把硬盘当内存用的性能魔法，全靠这一手！08-22](https://github.com/poemyang/p/19052513)[20.RPC的三大问题：跨语言、跨平台通信的终极解决方案是如何炼成的？08-27](https://github.com/poemyang/p/19060527)[21.从文本到二进制：HTTP/2不止于性能，更是对HTTP/1核心语义的传承与革新08-28](https://github.com/poemyang/p/19061836)[22.从HPACK到多路复用，揭秘HTTP/2如何终结网络拥堵08-29](https://github.com/poemyang/p/19063734):[nuts坚果](https://jianyong.org)[23.站在巨人的肩膀上：gRPC通过HTTP/2构建云原生时代的通信标准09-01](https://github.com/poemyang/p/19068100)[24.gRPC不是银弹：为内网极致性能，如何设计自己的RPC协议？09-03](https://github.com/poemyang/p/19071487)[25.从JSON到Protobuf，深入序列化方案的选型与原理09-04](https://github.com/poemyang/p/19073206)[26.“卧槽，系统又崩了！”——别慌，这也许是你看过最通俗易懂的分布式入门09-05](https://github.com/poemyang/p/19074847)[27.海量数据如何“安家”？一文读懂哈希、范围和一致性哈希三大分片策略09-08](https://github.com/poemyang/p/19079520)[28.“你还活着吗？” “我没死，只是网卡了！”——来自分布式世界的“生死契约”09-09](https://github.com/poemyang/p/19082361)[29.“凭什么说你比我先？”——没有上帝时钟，如何判断“谁先谁后”？09-12](https://github.com/poemyang/p/19087563)[30.“鸡蛋不能放一个篮子里”，如何确保千亿数据万无一失？09-15](https://github.com/poemyang/p/19092154)[31.系统里数据又“打架”了？让“少数服从多数”来终结这场混乱！09-18](https://github.com/poemyang/p/19097975)[32.技术圈的“绯闻女孩”：Gossip是如何把八卦秘密传遍全网的？09-19](https://github.com/poemyang/p/19100196)[33.绯闻女孩不只会八卦：从“验明正身”到“抓内鬼”，Gossip的进阶玩法09-20](https://github.com/poemyang/p/19101931)[34.从混沌到秩序：Java共享内存模型如何通过显式约束驯服并发？09-23](https://github.com/poemyang/p/19106679)[35.一把锁的两种承诺：synchronized如何同时保证互斥与内存可见性？09-24](https://github.com/poemyang/p/19108676)[36.从MESA模型到锁升级：synchronized性能逆袭的底层逻辑09-25](https://github.com/poemyang/p/19110705)[37.揭秘JUC：volatile与CAS，并发编程的两大基石09-27](https://github.com/poemyang/p/19114881)[38.“不要通过共享内存来通信”——深入理解Golang并发模型与CSP理论10-13](https://github.com/poemyang/p/19139419)[39.Goroutine间的“灵魂管道”：Channel如何实现数据同步与因果传递？10-14](https://github.com/poemyang/p/19142146)[40.“一切皆文件”：揭秘LINUX I/O与虚拟内存的底层设计哲学10-15](https://github.com/poemyang/p/19143895)[41.你的程序为何卡顿？从LINUX I/O三大模式寻找答案10-16](https://github.com/poemyang/p/19146666)[42.单线程如何撑起百万连接？I/O多路复用：现代网络架构的基石10-17](https://github.com/poemyang/p/19148798)[43.从C10K到Reactor：事件驱动，如何重塑高并发服务器的网络架构10-20](https://github.com/poemyang/p/19153675)[44.职责分离的艺术：剖析主从Reactor模型如何实现极致的并发性能10-21](https://github.com/poemyang/p/19156356)

45.“化零为整”的智慧：内存池如何绕过系统调用和GC，构建性能的护城河10-22

收起

**内存池：精打细算的内存管家**
在高性能系统（如网络服务器）的极致优化中，当处理器和I/O的瓶颈被逐一攻克后，内存管理便成为决定系统延迟和吞吐量的最后一道，也是最关键的一道关隘。传统的内存分配方式在这种场景下显得力不从心，催生了通过内存池（Memory Pool）作为管理策略。
在C/C++或Java等语言中，依赖系统默认的内存分配机制（如malloc或new）在高并发场景下会引发一系列性能灾难。
1）高昂的系统调用开销：每次内存分配/释放都可能陷入内核态，这是一个非常耗时的操作。在高频次的请求/响应循环中，这些开销会迅速累积。
2）内存碎片化：频繁申请和释放大小不一的内存块，会在内存中留下大量不连续的、难以利用的“空洞”，即外部碎片，最终导致即使总空闲内存充足，也无法分配出所需的大块内存。
3）锁竞争：为了保证线程安全，全局的内存分配器通常需要加锁。在多核环境下，这把锁会成为激烈的争抢点，严重限制系统的并发扩展能力。
![image](https://img2024.cnblogs.com/blog/757914/202510/757914-20251022221054258-1630161816.png)

**内存池实现**
内存池的核心思想是“化零为整，按需分配”。与其在每次需要时都向操作系统“零售”一小块内存，不如在程序启动时一次性“批发”一大块连续的内存空间。应用程序自己充当这块内存的“管家”，当需要内存时，从这个私有的“池子”里快速切分一块；用完后，再将其归还给池子，而不是操作系统。
如何高效地管理这个“池子”是一门艺术，常见的内存池化方式有三种。
1）链表维护空闲内存地址：通过链表管理空闲内存块地址。分配时从链表中取出空闲块；释放时将块地址重新加入链表。优点是实现简单，支持任意大小内存分配；缺点是频繁分配释放小块内存可能导致内存碎片，降低利用率。
2）定长内存空间分配：将内存池划分为固定大小的内存块。分配时直接返回空闲块；释放时将块归还内存池。优点是避免内存碎片，分配释放效率高；缺点是请求大小非整数倍时可能浪费内存。
3）多段定长池分配：将内存池划分为多个段，每段包含不同大小的内存块（如16B、32B、64B）。分配时根据请求大小选择合适的段并返回内存块；释放时将块归还对应段。优点是避免碎片并减少浪费，适合分配多种大小内存块的场景。

**堆外内存**
对于Java这类运行在虚拟机上的语言，即便使用了内存池，如果池子本身建立在Java虚拟机堆内，依然面临两大瓶颈。
1）数据拷贝：网络数据从内核缓冲区到应用程序，标准路径是内核空间到Java虚拟机堆内存。这次拷贝在高吞吐量下是巨大的性能损耗。
2）GC停顿（Stop-The-World）：堆内内存池中的大量小对象会给垃圾回收器（GC）带来沉重负担，可能引发不可预测的GC停顿，对低延迟应用是致命的。
堆外内存（Off-Heap Memory）是指不受Java虚拟机垃圾回收器管理的内存，在高性能网络编程和大数据处理中尤为重要。使用堆外内存的好处主要有两方面。
1）避免数据拷贝：数据可以直接从内核空间到堆外内存，省去了到Java虚拟机堆的拷贝，接近零拷贝（Zero-Copy），极大提升I/O效率。
2）消除GC影响：由于不受GC管理，堆外内存的分配和释放完全由程序手动控制（通常与内存池结合），从而避免了GC停顿带来的性能抖动，让服务响应时间更平滑、可预测。
在处理网络数据时，应首选使用堆外内存。当系统需要分配内存时，它会首先尝试从内存池中获取堆外内存。如果内存池中没有足够的堆外内存，尝试从系统中分配堆外内存。当不再需要这块内存时，应将这块内存归还给内存池，而非直接释放。
![image]()

**未完待续**

**很高兴与你相遇！如果你喜欢本文内容，记得关注哦**
